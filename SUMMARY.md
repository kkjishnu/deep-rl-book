# Summary

## Introduction to Deep RL

* [Introduction](README.md)
* [Review](recap-reinforcement-learning.md)
  * Reinforcement Learning
  * Deep Learning
* [Why is deep learning useful for RL?](neural-networks-in-rl.md)
* [Challenges of Deep RL](value-optimization.md)
* [Landscape of methods](landscape-of-deep-rl-methods.md)

## Value Function Estimation

* [Introduction](introduction-to-value-optimization.md)
* [Neural-fitted Q iteration \(NFQ\)](introduction-to-value-optimization/neural-fitted-q-iteration.md)
* [Deep Q Networks \(DQN\)](deep-q-networks.md)
* [DQN Extensions](dqn-variants.md)
  * [Double DQN](dqn-variants/double-dqn.md)
  * Dueling DQN
  * Prioritized Experience Replay
  * Normalized Advantage Function
  * Bootstrapped DQN
* [Applications](applications-td-gammon.md)
  * [TD-Gammon \(1992\)](applications-td-gammon/td-gammon.md)

## Policy Search

* [Introduction](policy-search/introduction.md)
* [The REINFORCE gradient estimator](policy-search/the-reinforce-gradient-estimator.md)
* Policy Gradient Extensions
  * Trust Region Policy Optimization
  * Natural Policy Gradients
  * Proximal Policy Optimization
* [Actor-Critic Paradigm](policy-search/actor-critic-paradigm.md)
* [Distributed RL](policy-search/distributed-learning.md)
  * Gorila
* Advantage Actor-Critic \(A2C\)
* Applications
  * Robotics

## Model Estimation

* Introduction
* Monte Carlo Tree Search \(MCTS\)
* UCT-to-Realtime
* [Applications](model-estimation/applications.md)
  * [AlphaGo \(2017\)](model-estimation/applications/alphago.md)

## Hierarchical RL

* [Introduction to Hierarchical RL](hierarchical-rl/introduction.md)
* Options
* Options DQN
* Option-Critic Architecture
* Hierarchical DQN
* Feudal Networks

## Inverse RL

## Multi-Agent RL

